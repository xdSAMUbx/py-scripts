{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66ae45e",
   "metadata": {},
   "source": [
    "# Librerias a usar para el parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4480c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Literal\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import math as mh\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db99c51",
   "metadata": {},
   "source": [
    "# Mejoras de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ffd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "escala: Dict[str, float] = {'0': 1e3, '6': 1e4, '8': 1e5}\n",
    "orden: Dict[str,int] = {'1':3, '2':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c89940",
   "metadata": {},
   "source": [
    "# Paths y REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2f2577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths y expresiones\n",
    "\n",
    "PATH = Path(\"G:\\\\Otros ordenadores\\\\Mi PC\\\\IGAC\\\\archivosPrueba\\\\Archivos_Pruebas\\\\L5_GSI_1\")\n",
    "L5Crudos = PATH / 'CRUDOS_L5'\n",
    "L5Orden = PATH / 'Orden_L5' / 'L5_Principio_Linea;Fin_linea.txt'\n",
    "crudos = [p for p in L5Crudos.iterdir() if p.is_file() is True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f73fcf",
   "metadata": {},
   "source": [
    "# Estandarizador de Nomenclaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccc31522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que estandariza las nomenclaturas\n",
    "def vert_std(codigo:str) -> str:\n",
    "\n",
    "    # VERT: Patron que estandariza los vertices XXXX-XXXX-09\n",
    "    VERT_RE = re.compile(r'^([A-Z0-9]+)([A-Z]{2,4})(\\d{1,2})$')\n",
    "\n",
    "    code_mayusc = codigo.replace(\"-\", \"\").replace(\" \", \"\").upper()\n",
    "    m = VERT_RE.match(code_mayusc)\n",
    "    if m:\n",
    "        g1, g2, g3 = m.groups()\n",
    "        return f\"{g1}-{g2}-{g3}\"\n",
    "    \n",
    "    return codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1c01e",
   "metadata": {},
   "source": [
    "# Clasificador de Orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdf8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ini': 'B70-CW-7', 'fin': '23660003', 'sentido': 'I'},\n",
       " {'ini': '23660003', 'fin': 'B70-CW-7', 'sentido': 'R'},\n",
       " {'ini': '23660003', 'fin': 'A2-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A2-CB-3', 'fin': '23660003', 'sentido': 'R'},\n",
       " {'ini': 'A2-CB-3', 'fin': 'A3-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A3-CB-3', 'fin': 'A2-CB-3', 'sentido': 'R'},\n",
       " {'ini': 'A3-CB-3', 'fin': '4-CB-3', 'sentido': 'I'},\n",
       " {'ini': '4-CB-3', 'fin': 'A3-CB-3', 'sentido': 'R'},\n",
       " {'ini': '4-CB-3', 'fin': '5-CB-3', 'sentido': 'I'},\n",
       " {'ini': '5-CB-3', 'fin': '4-CB-3', 'sentido': 'R'},\n",
       " {'ini': '5-CB-3', 'fin': '6-CB-3', 'sentido': 'I'},\n",
       " {'ini': '6-CB-3', 'fin': '5-CB-3', 'sentido': 'R'},\n",
       " {'ini': '6-CB-3', 'fin': '23189001', 'sentido': 'I'},\n",
       " {'ini': '23189001', 'fin': '6-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189001', 'fin': '8-CB-3', 'sentido': 'I'},\n",
       " {'ini': '8-CB-3', 'fin': '23189001', 'sentido': 'R'},\n",
       " {'ini': '8-CB-3', 'fin': '9-CB-3', 'sentido': 'I'},\n",
       " {'ini': '9-CB-3', 'fin': '8-CB-3', 'sentido': 'R'},\n",
       " {'ini': '9-CB-3', 'fin': '10-CB-3', 'sentido': 'I'},\n",
       " {'ini': '10-CB-3', 'fin': '9-CB-3', 'sentido': 'R'},\n",
       " {'ini': '10-CB-3', 'fin': '23189002', 'sentido': 'I'},\n",
       " {'ini': '23189002', 'fin': '10-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189002', 'fin': '12-CB-3', 'sentido': 'I'},\n",
       " {'ini': '12-CB-3', 'fin': '23189002', 'sentido': 'R'},\n",
       " {'ini': '12-CB-3', 'fin': '13-CB-3', 'sentido': 'I'},\n",
       " {'ini': '13-CB-3', 'fin': '12-CB-3', 'sentido': 'R'},\n",
       " {'ini': '13-CB-3', 'fin': '23189003', 'sentido': 'I'},\n",
       " {'ini': '23189003', 'fin': '13-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189003', 'fin': 'A16-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A16-CB-3', 'fin': '23189003', 'sentido': 'R'},\n",
       " {'ini': 'A16-CB-3', 'fin': '23189004', 'sentido': 'I'},\n",
       " {'ini': '23189004', 'fin': 'A16-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189004', 'fin': '18-CB-3', 'sentido': 'I'},\n",
       " {'ini': '18-CB-3', 'fin': '23189004', 'sentido': 'R'},\n",
       " {'ini': '18-CB-3', 'fin': '23189005', 'sentido': 'I'},\n",
       " {'ini': '23189005', 'fin': '18-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189005', 'fin': '19-CB-3', 'sentido': 'I'},\n",
       " {'ini': '19-CB-3', 'fin': '23189005', 'sentido': 'R'},\n",
       " {'ini': '19-CB-3', 'fin': '15-TE-2', 'sentido': 'I'},\n",
       " {'ini': '15-TE-2', 'fin': '19-CB-3', 'sentido': 'R'},\n",
       " {'ini': '15-TE-2', 'fin': 'A20-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A20-CB-3', 'fin': '15-TE-2', 'sentido': 'R'},\n",
       " {'ini': 'A20-CB-3', 'fin': 'A21-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A21-CB-3', 'fin': 'A20-CB-3', 'sentido': 'R'},\n",
       " {'ini': 'A21-CB-3', 'fin': 'A22-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A22-CB-3', 'fin': 'A21-CB-3', 'sentido': 'R'},\n",
       " {'ini': 'A22-CB-3', 'fin': '23-CB-3', 'sentido': 'I'},\n",
       " {'ini': '23-CB-3', 'fin': 'A22-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23-CB-3', 'fin': '23189006', 'sentido': 'I'},\n",
       " {'ini': '23189006', 'fin': '23-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23189006', 'fin': 'A25-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A25-CB-3', 'fin': '23189006', 'sentido': 'R'},\n",
       " {'ini': 'A25-CB-3', 'fin': 'A26-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A26-CB-3', 'fin': 'A25-CB-3', 'sentido': 'R'},\n",
       " {'ini': 'A26-CB-3', 'fin': '27-CB-3', 'sentido': 'I'},\n",
       " {'ini': '27-CB-3', 'fin': 'A26-CB-3', 'sentido': 'R'},\n",
       " {'ini': '27-CB-3', 'fin': '28-CB-3', 'sentido': 'I'},\n",
       " {'ini': '28-CB-3', 'fin': '27-CB-3', 'sentido': 'R'},\n",
       " {'ini': '28-CB-3', 'fin': '23162001', 'sentido': 'I'},\n",
       " {'ini': '23162001', 'fin': '28-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23162001', 'fin': '23162002', 'sentido': 'I'},\n",
       " {'ini': '23162002', 'fin': '23162001', 'sentido': 'R'},\n",
       " {'ini': '23162002', 'fin': '23162003', 'sentido': 'I'},\n",
       " {'ini': '23162003', 'fin': '23162002', 'sentido': 'R'},\n",
       " {'ini': '23162003', 'fin': '23162004', 'sentido': 'I'},\n",
       " {'ini': '23162004', 'fin': '23162003', 'sentido': 'R'},\n",
       " {'ini': '23162004', 'fin': '23162005', 'sentido': 'I'},\n",
       " {'ini': '23162005', 'fin': '23162004', 'sentido': 'R'},\n",
       " {'ini': '23162005', 'fin': '23162006', 'sentido': 'I'},\n",
       " {'ini': '23162006', 'fin': '23162005', 'sentido': 'R'},\n",
       " {'ini': '23162006', 'fin': 'A38-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A38-CB-3', 'fin': '23162006', 'sentido': 'R'},\n",
       " {'ini': 'A38-CB-3', 'fin': '39-CB-3', 'sentido': 'I'},\n",
       " {'ini': '39-CB-3', 'fin': 'A38-CB-3', 'sentido': 'R'},\n",
       " {'ini': '39-CB-3', 'fin': '23001001', 'sentido': 'I'},\n",
       " {'ini': '23001001', 'fin': '39-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23001001', 'fin': 'A40-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A40-CB-3', 'fin': '23001001', 'sentido': 'R'},\n",
       " {'ini': 'A40-CB-3', 'fin': '23001002', 'sentido': 'I'},\n",
       " {'ini': '23001002', 'fin': 'A40-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23001002', 'fin': 'A42-CB-3', 'sentido': 'I'},\n",
       " {'ini': 'A42-CB-3', 'fin': '23001002', 'sentido': 'R'},\n",
       " {'ini': 'A42-CB-3', 'fin': '23001003', 'sentido': 'I'},\n",
       " {'ini': '23001003', 'fin': 'A42-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23001003', 'fin': '44-CB-3', 'sentido': 'I'},\n",
       " {'ini': '44-CB-3', 'fin': '23001003', 'sentido': 'R'},\n",
       " {'ini': '44-CB-3', 'fin': '23001004', 'sentido': 'I'},\n",
       " {'ini': '23001004', 'fin': '44-CB-3', 'sentido': 'R'},\n",
       " {'ini': '23001004', 'fin': '23001005', 'sentido': 'I'},\n",
       " {'ini': '23001005', 'fin': '23001004', 'sentido': 'R'},\n",
       " {'ini': '23001005', 'fin': 'GPSCRT8A', 'sentido': 'I'},\n",
       " {'ini': 'GPSCRT8A', 'fin': '23001005', 'sentido': 'R'},\n",
       " {'ini': 'GPSCRT8A', 'fin': '23001006', 'sentido': 'I'},\n",
       " {'ini': '23001006', 'fin': 'GPSCRT8A', 'sentido': 'R'},\n",
       " {'ini': '23001006', 'fin': '23001007', 'sentido': 'I'},\n",
       " {'ini': '23001007', 'fin': '23001006', 'sentido': 'R'},\n",
       " {'ini': '23001007', 'fin': '23001008', 'sentido': 'I'},\n",
       " {'ini': '23001008', 'fin': '23001007', 'sentido': 'R'},\n",
       " {'ini': '23001008', 'fin': '4-BE-2', 'sentido': 'I'},\n",
       " {'ini': '4-BE-2', 'fin': '23001008', 'sentido': 'R'},\n",
       " {'ini': '4-BE-2', 'fin': 'A5-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A5-BE-2', 'fin': '4-BE-2', 'sentido': 'R'},\n",
       " {'ini': 'A5-BE-2', 'fin': '23001009', 'sentido': 'I'},\n",
       " {'ini': '23001009', 'fin': 'A5-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001009', 'fin': '7-BE-2', 'sentido': 'I'},\n",
       " {'ini': '7-BE-2', 'fin': '23001009', 'sentido': 'R'},\n",
       " {'ini': '7-BE-2', 'fin': '8-BE-2', 'sentido': 'I'},\n",
       " {'ini': '8-BE-2', 'fin': '7-BE-2', 'sentido': 'R'},\n",
       " {'ini': '8-BE-2', 'fin': '9-BE-2', 'sentido': 'I'},\n",
       " {'ini': '9-BE-2', 'fin': '8-BE-2', 'sentido': 'R'},\n",
       " {'ini': '9-BE-2', 'fin': '23001010', 'sentido': 'I'},\n",
       " {'ini': '23001010', 'fin': '9-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001010', 'fin': '23001011', 'sentido': 'I'},\n",
       " {'ini': '23001011', 'fin': '23001010', 'sentido': 'R'},\n",
       " {'ini': '23001011', 'fin': '23001012', 'sentido': 'I'},\n",
       " {'ini': '23001012', 'fin': '23001011', 'sentido': 'R'},\n",
       " {'ini': '23001012', 'fin': '12-BE-2', 'sentido': 'I'},\n",
       " {'ini': '12-BE-2', 'fin': '23001012', 'sentido': 'R'},\n",
       " {'ini': '12-BE-2', 'fin': '23001013', 'sentido': 'I'},\n",
       " {'ini': '23001013', 'fin': '12-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001013', 'fin': 'A14-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A14-BE-2', 'fin': '23001013', 'sentido': 'R'},\n",
       " {'ini': 'A14-BE-2', 'fin': '23001014', 'sentido': 'I'},\n",
       " {'ini': '23001014', 'fin': 'A14-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001014', 'fin': '16-BE-2', 'sentido': 'I'},\n",
       " {'ini': '16-BE-2', 'fin': '23001014', 'sentido': 'R'},\n",
       " {'ini': '16-BE-2', 'fin': '23001015', 'sentido': 'I'},\n",
       " {'ini': '23001015', 'fin': '16-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001015', 'fin': '18-BE-2', 'sentido': 'I'},\n",
       " {'ini': '18-BE-2', 'fin': '23001015', 'sentido': 'R'},\n",
       " {'ini': '18-BE-2', 'fin': '23001016', 'sentido': 'I'},\n",
       " {'ini': '23001016', 'fin': '18-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001016', 'fin': '23001017', 'sentido': 'I'},\n",
       " {'ini': '23001017', 'fin': '23001016', 'sentido': 'R'},\n",
       " {'ini': '23001017', 'fin': '20-BE-2', 'sentido': 'I'},\n",
       " {'ini': '20-BE-2', 'fin': '23001017', 'sentido': 'R'},\n",
       " {'ini': '20-BE-2', 'fin': '23001018', 'sentido': 'I'},\n",
       " {'ini': '23001018', 'fin': '20-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001018', 'fin': '21-BE-2', 'sentido': 'I'},\n",
       " {'ini': '21-BE-2', 'fin': '23001018', 'sentido': 'R'},\n",
       " {'ini': '21-BE-2', 'fin': '22-BE-2', 'sentido': 'I'},\n",
       " {'ini': '22-BE-2', 'fin': '21-BE-2', 'sentido': 'R'},\n",
       " {'ini': '22-BE-2', 'fin': '23001019', 'sentido': 'I'},\n",
       " {'ini': '23001019', 'fin': '22-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23001019', 'fin': '24-BE-2', 'sentido': 'I'},\n",
       " {'ini': '24-BE-2', 'fin': '23001019', 'sentido': 'R'},\n",
       " {'ini': '24-BE-2', 'fin': '23555013', 'sentido': 'I'},\n",
       " {'ini': '23555013', 'fin': '24-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23555013', 'fin': '23555014', 'sentido': 'I'},\n",
       " {'ini': '23555014', 'fin': '23555013', 'sentido': 'R'},\n",
       " {'ini': '23555014', 'fin': '26-BE-2', 'sentido': 'I'},\n",
       " {'ini': '26-BE-2', 'fin': '23555014', 'sentido': 'R'},\n",
       " {'ini': '26-BE-2', 'fin': '23555015', 'sentido': 'I'},\n",
       " {'ini': '23555015', 'fin': '26-BE-2', 'sentido': 'R'},\n",
       " {'ini': '23555015', 'fin': 'A27-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A27-BE-2', 'fin': '23555015', 'sentido': 'R'},\n",
       " {'ini': 'A27-BE-2', 'fin': 'A28-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A28-BE-2', 'fin': 'A27-BE-2', 'sentido': 'R'},\n",
       " {'ini': 'A28-BE-2', 'fin': '29-BE-2', 'sentido': 'I'},\n",
       " {'ini': '29-BE-2', 'fin': 'A28-BE-2', 'sentido': 'R'},\n",
       " {'ini': '29-BE-2', 'fin': '30-BE-2', 'sentido': 'I'},\n",
       " {'ini': '30-BE-2', 'fin': '29-BE-2', 'sentido': 'R'},\n",
       " {'ini': '30-BE-2', 'fin': 'A31-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A31-BE-2', 'fin': '30-BE-2', 'sentido': 'R'},\n",
       " {'ini': 'A31-BE-2', 'fin': 'A32-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A32-BE-2', 'fin': 'A31-BE-2', 'sentido': 'R'},\n",
       " {'ini': 'A32-BE-2', 'fin': 'A33-BE-2', 'sentido': 'I'},\n",
       " {'ini': 'A33-BE-2', 'fin': 'A32-BE-2', 'sentido': 'R'},\n",
       " {'ini': 'A33-BE-2', 'fin': 'B33-CW-7', 'sentido': 'I'},\n",
       " {'ini': 'B33-CW-7', 'fin': 'A33-BE-2', 'sentido': 'R'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función que ordena el archivo orden\n",
    "def clasi_orden(forden:Path, headline:bool = True) -> List[Dict[str,str]]:\n",
    "    output = []\n",
    "\n",
    "    if headline:\n",
    "        with open(forden, \"r\", encoding=\"utf-8\") as f:\n",
    "            # suponemos primera línea encabezado\n",
    "            for i, linea in enumerate(f.readlines()[1:]):\n",
    "                linea = linea.strip()\n",
    "                if not linea or \";\" not in linea:\n",
    "                    continue\n",
    "                a, b = linea.split(\";\")\n",
    "                a = vert_std(a)\n",
    "                b = vert_std(b)\n",
    "                if i % 2 == 0:\n",
    "                    output.append({\"ini\":a,\"fin\":b,\"sentido\":\"I\"})\n",
    "                else:\n",
    "                    output.append({\"ini\":a,\"fin\":b,\"sentido\":\"R\"})\n",
    "    else:\n",
    "        with open(forden, \"r\", encoding=\"utf-8\") as f:\n",
    "            # suponemos primera línea encabezado\n",
    "            for i, linea in enumerate(f.readlines()):\n",
    "                linea = linea.strip()\n",
    "                if not linea or \";\" not in linea:\n",
    "                    continue\n",
    "                a, b = linea.split(\";\")\n",
    "                a = vert_std(a)\n",
    "                b = vert_std(b)\n",
    "                if i % 2 == 0:\n",
    "                    output.append({\"ini\":a,\"fin\":b,\"sentido\":\"I\"})\n",
    "                else:\n",
    "                    output.append({\"ini\":a,\"fin\":b,\"sentido\":\"R\"})\n",
    "\n",
    "    with open(\"../LeicaGSI_LS10_Parser/data/orden_niv.json\", \"w\") as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "\n",
    "    return output\n",
    "\n",
    "clasi_orden(L5Orden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2f59d",
   "metadata": {},
   "source": [
    "# Generador de Fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e976420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_fecha(fname:str):\n",
    "\n",
    "    # FECHA6: Extrae fechas\n",
    "    FECHA6_RE = re.compile(r'(\\d{6})')\n",
    "\n",
    "    m = FECHA6_RE.search(fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    \n",
    "    y, mth, d = int(m.group(1)[:2]), int(m.group(1)[2:4]), int(m.group(1)[4:6])\n",
    "\n",
    "    # regla para siglo: 00–49 → 2000s, 50–99 → 1900s\n",
    "    year = 2000 + y if y < 50 else 1900 + y\n",
    "\n",
    "    try:\n",
    "        return date(year, mth, d).isoformat()\n",
    "    except ValueError:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8904c",
   "metadata": {},
   "source": [
    "# Calculo Colimación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "885125be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colimacion(lineas,file):\n",
    "    \"\"\"\n",
    "    La función colimación tiene como proposito calcular el error de colimación en metros para posteriormente\n",
    "    ser tenido en cuenta en el ajuste. La metodología con la que es calculada es la mencionada en el manual de \n",
    "    Leica para equipos LS10/LS15.\n",
    "    \n",
    "    Parametros:\n",
    "        - lineas: Es el conjunto de lineas del archivo para que la misma función examine si hay o no las mediciones de\n",
    "            colimación con los nombres presentados en el manual de Leica A1, B1, B2 y A2.\n",
    "\n",
    "        - file: Es el archivo que se desea procesar para la automatización del proceso.\n",
    "\n",
    "    Retorna: Retorna un vector con dos valores, un real y un string, los cuales son descritos acontinuación:\n",
    "        1) El real es el cálculo de la colimación ofrecido en el manual del equipo leica y que es también mencionado\n",
    "            en los equipos de trimble. El método de colimación es mediante el método de forstner y posteriormente\n",
    "            es pasado a metros con 4 decimales independientementes si la medida esta en mm, decimas de mm o centecimas\n",
    "            de mm.\n",
    "\n",
    "        2) El segundo valor es referente al tipo de archivo descargado, los archivos de leica tipo GSI permiten\n",
    "            la descarga de la información en 8 o 16 bits, lo cual afecta el número de caracteres que se imprimen en \n",
    "            el archivo de texto, esta información puede ser relevante para el control de calidad según los lineamientos\n",
    "            que estan siendo actualizados por el equipo de nivelacion.\n",
    "\n",
    "    TODO: La presente función contempla registros posiblemente ofrecidos por el equipo LEICA DNA 03, se debe realizar\n",
    "        el código que permita obtener la información de ambos equipos debe ser desarrollado o complementado a este.\n",
    "    \"\"\"\n",
    "    # Patron de las medidas de colimación leica \n",
    "    patron_colimacion = r'^(\\d{6})\\+(\\S{8,16})\\s+(\\S{6})([+-]\\S{8,16})\\s(\\S{6})([+-]\\S{8,16})'\n",
    "    colimacion = []\n",
    "    tipo_gsi = None\n",
    "\n",
    "    # Recorre todas las líneas del archivo \n",
    "    for linea in lineas:\n",
    "        linea = linea.strip()\n",
    "        try:\n",
    "            pat_col = re.search(patron_colimacion,linea) # patron de colimación\n",
    "            if pat_col is not None: # Verifica si el patron de colimación existe\n",
    "                try:\n",
    "                    tipo_gsi = f'{len(pat_col.group(2))} bits' # Obtiene el tipo de archivo gsi que se esta manejando\n",
    "                    data_col = ['A1','B1','B2','A2']\n",
    "                    if pat_col.group(2).lstrip('0') in data_col:\n",
    "                        try:\n",
    "                            conversor = escala.get(pat_col.group(3)[-1])\n",
    "                            if pat_col.group(6) is not None and pat_col.group(4) is not None and conversor is not None:\n",
    "                                alt = float(pat_col.group(6))\n",
    "                                dist = float(pat_col.group(4))\n",
    "                                col_data = {\n",
    "                                    \"id_colimacion\": pat_col.group(2).lstrip('0'),\n",
    "                                    \"alt.obs\" : float(alt)/conversor,\n",
    "                                    \"dist.hor\": float(dist)/conversor\n",
    "                                }\n",
    "                                colimacion.append(col_data)\n",
    "                            else:\n",
    "                                pass\n",
    "\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Error al obtener los datos de colimación en: {Path(file)}\")\n",
    "                            return None\n",
    "                    else:\n",
    "                        pass\n",
    "                except Exception as e:\n",
    "                    print(f\"El error {e} se presenta en el archivo: {Path(file)}\")\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(f\"El error {e} se presenta en el archivo: {Path(file)}\")\n",
    "\n",
    "    try:\n",
    "        output = mh.atan(((colimacion[0]['alt.obs'] - colimacion[1]['alt.obs']) + \n",
    "                            (colimacion[2]['alt.obs'] - colimacion[3]['alt.obs'])) / \n",
    "                            ((colimacion[0]['dist.hor'] - colimacion[1]['dist.hor']) + \n",
    "                            (colimacion[2]['dist.hor'] - colimacion[3]['dist.hor']))) * (6378137/3600)\n",
    "        return [round(output,5),tipo_gsi]\n",
    "    except Exception as e:\n",
    "                        print(f\"El error: {e} \\nSe encuentra en el archivo: {Path(file)}\")\n",
    "                        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cada4",
   "metadata": {},
   "source": [
    "# Obtención de los datos crudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ca0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_leica_dna03(archivos,json_file):\n",
    "\n",
    "    ruta = Path(json_file)\n",
    "\n",
    "    if not ruta.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el JSON en: {ruta}\")\n",
    "\n",
    "    patron_metodo_observacion = r'^(41\\S{4})\\+(\\S{8,16})'\n",
    "    patron_inicio = r'^(\\d{6,7})\\+(\\S{8,16})\\s(83\\S{4})([+-]\\S{8,16})'\n",
    "    patron_fin = r'^(\\d{6,7})\\+(\\S{8,16})\\s(573\\S{3})([+-]\\S{8,16})\\s(574\\S{3})([+-]\\S{8,16})\\s(83\\S{4})([+-]\\S{8,16})'\n",
    "\n",
    "    orden_archivo = None\n",
    "    nom_ini = None\n",
    "    nom_fin = None\n",
    "    dist_hor_total = None\n",
    "    dif_dist_hor = None\n",
    "    ceros_ini = None\n",
    "    alt_obs = None\n",
    "    datos_crudos = []\n",
    "\n",
    "    with open(Path(json_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        print(\"Archivo json cargado\")\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for archivo in archivos:\n",
    "        with open(Path(archivo),\"r\") as file:\n",
    "            lineas = file.readlines()\n",
    "            col = colimacion(lineas,archivo)\n",
    "            if col is None:\n",
    "                raise ValueError (f'No se logro calcular la colimación')\n",
    "            \n",
    "            for linea in lineas:\n",
    "                linea = linea.strip()\n",
    "                # Permite obtener el orden del archivo (si la nivelación se realizo con metodología de orden 1, 2 o 3)\n",
    "                if re.search(patron_metodo_observacion,linea) is not None:\n",
    "                    orden_archivo = orden.get(linea[-1])\n",
    "                \n",
    "                # Permite obtener el nombre y la medida con la cual se inicio el vértice a nivelar\n",
    "                if re.search(patron_inicio, linea):\n",
    "                    est_inicio = re.search(patron_inicio, linea)\n",
    "                    if est_inicio is not None:\n",
    "                        nom_ini = vert_std(est_inicio.group(2).lstrip('0'))\n",
    "                        ceros_ini = float(est_inicio.group(4))\n",
    "\n",
    "                # Permite obtener el nombre, altura, distancia, diferencia de distancias del vértice al cual se llega\n",
    "                if re.search(patron_fin, linea):\n",
    "                    est_fin = re.search(patron_fin,linea)\n",
    "                    if est_fin is not None:\n",
    "                        nomen = vert_std(est_fin.group(2).lstrip('0'))\n",
    "                        if any(ptos['fin'] == nomen for ptos in json_data):\n",
    "                            nom_fin = vert_std(est_fin.group(2).lstrip('0')) # Obtiene el nombre del vértice\n",
    "                            conversor = escala.get(est_fin.group(3)[-1]) # Obtiene el conversor\n",
    "                            if conversor is not None:\n",
    "                                dif_dist_hor = float(est_fin.group(4))/conversor # Obtiene la diferencia de distancias horizontales (balanceo)\n",
    "                                dist_hor_total = float(est_fin.group(6))/conversor # Obtiene la distancia total\n",
    "                                alt_obs = float(est_fin.group(8))/conversor\n",
    "                                if ceros_ini is not None:\n",
    "                                    ceros_ini = ceros_ini/conversor\n",
    "                        \n",
    "                                # Mejorar el método de entrega de las observaciones, es preferible indicar en que sistema esta (mm,dmm,cmm)\n",
    "                                new_data = {\n",
    "                                    \"ini\": nom_ini,\n",
    "                                    \"fin\": nom_fin,\n",
    "                                    \"dis.total\": dist_hor_total,\n",
    "                                    \"dif.dist.hor\": dif_dist_hor,\n",
    "                                    \"ceros.iniciales\": ceros_ini,\n",
    "                                    \"dif.alt.obs\": alt_obs,\n",
    "                                    \"orden_obs\": orden_archivo,\n",
    "                                    \"colimacion\": col[0],\n",
    "                                    \"tipo.archivo\": col[1],\n",
    "                                    \"nombre.archivo\": archivo.name,\n",
    "                                    \"fecha\": ext_fecha(archivo.name)\n",
    "                                }\n",
    "\n",
    "                                datos_crudos.append(new_data)       \n",
    "\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "    return datos_crudos\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc70be",
   "metadata": {},
   "source": [
    "# Parser Leica DNA03 8 - 16 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cdf18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_ini(files, order_info, output_info_xlsx):\n",
    "\n",
    "    datos_crudos = parser_leica_dna03(files,order_info)\n",
    "\n",
    "    new_info = {(n[\"ini\"], n[\"fin\"]): n for n in datos_crudos}\n",
    "\n",
    "    with open(order_info, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "    for data in json_data:\n",
    "        clave = (data['ini'], data['fin'])\n",
    "        if clave in new_info:\n",
    "            for k, v in new_info[clave].items():\n",
    "                if k not in (\"ini\", \"fin\"):   # proteger claves\n",
    "                    data[k] = v \n",
    "\n",
    "    with open(order_info, \"w\") as f:\n",
    "        json.dump(json_data, f, indent=2) \n",
    "        \n",
    "    pd.DataFrame(json_data).to_excel(output_info_xlsx, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d553a",
   "metadata": {},
   "source": [
    "# Parser de estaciones de Inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "664ebccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo json cargado\n"
     ]
    }
   ],
   "source": [
    "archivos = sorted([p for p in L5Crudos.iterdir() if p.is_file() is True])\n",
    "\n",
    "parser_ini(archivos,\"../LeicaGSI_LS10_Parser/data/orden_niv.json\",\"../LeicaGSI_LS10_Parser/data/prueba_crudos.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pc (3.13.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
